<!doctype html><html lang=ko dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>[혼공머신] 4주차 학습 내용 정리 | Halog</title>
<meta name=keywords content=","><meta name=description content="혼자 공부하는 머신러닝+딥러닝 4주차 학습 내용"><meta name=author content><link rel=canonical href=https://haservi.github.io/posts/books/hg-mldl/week-4/><meta name=google-site-verification content="G-MXZP81P04W"><link rel=stylesheet as=style crossorigin href=https://cdn.jsdelivr.net/gh/orioncactus/pretendard@v1.3.6/dist/web/static/pretendard.css><link crossorigin=anonymous href=/assets/css/stylesheet.css rel="preload stylesheet" as=style><link rel=icon href=https://haservi.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://haservi.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://haservi.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://haservi.github.io/apple-touch-icon.png><link rel=mask-icon href=https://haservi.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=ko href=https://haservi.github.io/posts/books/hg-mldl/week-4/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-1400973749140762" crossorigin=anonymous></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-RP5NDCM8J9"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-RP5NDCM8J9")}</script></head><body class=dark id=top><script>localStorage.getItem("pref-theme")==="light"&&document.body.classList.remove("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://haservi.github.io/ accesskey=h title="Halog (Alt + H)">Halog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://haservi.github.io/archives/ title=Archive><span>Archive</span></a></li><li><a href=https://haservi.github.io/categories/ title=Categories><span>Categories</span></a></li><li><a href=https://haservi.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://haservi.github.io/>홈</a>&nbsp;»&nbsp;<a href=https://haservi.github.io/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">[혼공머신] 4주차 학습 내용 정리</h1><div class=post-meta><span title='2025-07-27 16:00:15 +0900 +0900'>7월 27, 2025</span>&nbsp;·&nbsp;12 분</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>목차</span></summary><div class=inner><ul><li><a href=#%ea%b8%b0%eb%b3%b8-%ec%88%99%ec%a0%9c aria-label="기본 숙제">기본 숙제</a></li><li><a href=#%eb%82%b4%ec%9a%a9-%ec%a0%95%eb%a6%ac aria-label="내용 정리">내용 정리</a><ul><li><a href=#%ea%b2%b0%ec%a0%95-%ed%8a%b8%eb%a6%ac aria-label="결정 트리">결정 트리</a><ul><li><a href=#%eb%a1%9c%ec%a7%80%ec%8a%a4%ed%8b%b1-%ed%9a%8c%ea%b7%80%eb%a1%9c-%ec%99%80%ec%9d%b8-%eb%b6%84%eb%a5%98%ed%95%98%ea%b8%b0 aria-label="로지스틱 회귀로 와인 분류하기">로지스틱 회귀로 와인 분류하기</a></li></ul></li><li><a href=#%ea%b5%90%ec%b0%a8-%ea%b2%80%ec%a6%9d%ea%b3%bc-%ea%b7%b8%eb%a6%ac%eb%93%9c-%ec%84%9c%ec%b9%98 aria-label="교차 검증과 그리드 서치">교차 검증과 그리드 서치</a><ul><li><a href=#%ea%b2%80%ec%a6%9d-%ec%84%b8%ed%8a%b8 aria-label="검증 세트">검증 세트</a></li><li><a href=#%ea%b5%90%ec%b0%a8-%ea%b2%80%ec%a6%9d aria-label="교차 검증">교차 검증</a></li><li><a href=#%ed%95%98%ec%9d%b4%ed%8d%bc%ed%8c%8c%eb%9d%bc%eb%af%b8%ed%84%b0-%ed%8a%9c%eb%8b%9d aria-label="하이퍼파라미터 튜닝">하이퍼파라미터 튜닝</a></li><li><a href=#%eb%9e%9c%eb%8d%a4-%ec%84%9c%ec%b9%98 aria-label="랜덤 서치">랜덤 서치</a></li></ul></li><li><a href=#%ed%8a%b8%eb%a6%ac%ec%9d%98-%ec%95%99%ec%83%81%eb%b8%94 aria-label="트리의 앙상블">트리의 앙상블</a><ul><li><a href=#%ec%a0%95%ed%98%95-%eb%8d%b0%ec%9d%b4%ed%84%b0%ec%99%80-%eb%b9%84%ec%a0%95%ed%98%95-%eb%8d%b0%ec%9d%b4%ed%84%b0 aria-label="정형 데이터와 비정형 데이터">정형 데이터와 비정형 데이터</a></li><li><a href=#%eb%9e%9c%eb%8d%a4-%ed%8f%ac%eb%a0%88%ec%8a%a4%ed%8a%b8 aria-label="랜덤 포레스트">랜덤 포레스트</a></li><li><a href=#%ec%97%91%ec%8a%a4%ed%8a%b8%eb%9d%bc-%ed%8a%b8%eb%a6%ac aria-label="엑스트라 트리">엑스트라 트리</a></li><li><a href=#%ea%b7%b8%eb%a0%88%ec%9d%b4%eb%94%94%ec%96%b8%ed%8a%b8-%eb%b6%80%ec%8a%a4%ed%8c%85 aria-label="그레이디언트 부스팅">그레이디언트 부스팅</a></li><li><a href=#%ed%9e%88%ec%8a%a4%ed%86%a0%ea%b7%b8%eb%9e%a8-%ea%b8%b0%eb%b0%98-%ea%b7%b8%eb%a0%88%ec%9d%b4%eb%94%94%ec%96%b8%ed%8a%b8-%eb%b6%80%ec%8a%a4%ed%8c%85 aria-label="히스토그램 기반 그레이디언트 부스팅">히스토그램 기반 그레이디언트 부스팅</a></li></ul></li></ul></li></ul></div></details></div><div class=post-content><p><img alt=image loading=lazy src=/posts/books/hg-mldl/week-4/images/image-01.webp></p><h1 id=기본-숙제>기본 숙제<a hidden class=anchor aria-hidden=true href=#기본-숙제>#</a></h1><p>교차 검증을 그림으로 설명하기</p><p><img alt=image loading=lazy src=/posts/books/hg-mldl/week-4/images/image-05.webp></p><p>교차 검증의 장점</p><ul><li>모든 데이터 활용: 모든 데이터가 훈련과 테스트에 모두 사용됨</li><li>신뢰성 향상: 여러 번 검증하여 더 안정적인 성능 평가</li><li>과적합 방지: 특정 데이터 분할에 의존하지 않음</li></ul><h1 id=내용-정리>내용 정리<a hidden class=anchor aria-hidden=true href=#내용-정리>#</a></h1><h2 id=결정-트리>결정 트리<a hidden class=anchor aria-hidden=true href=#결정-트리>#</a></h2><p>결정 트리(Decision Tree)는 데이터를 분류하거나 예측하는 머신러닝 알고리즘입니다.</p><p>캔에 와인 이름 표기가 안돼 있어서 캔에 인쇄된 알코올 도수, 당도, pH 값으로 와인 종류를 구별해야합니다.</p><p>결정 트리의 장점은 해석하기 쉽고 직관적이라는 점이고, 단점은 과적합되기 쉽고 데이터가 조금만 바뀌어도 트리 구조가 크게 달라질 수 있다는 점입니다.</p><h3 id=로지스틱-회귀로-와인-분류하기>로지스틱 회귀로 와인 분류하기<a hidden class=anchor aria-hidden=true href=#로지스틱-회귀로-와인-분류하기>#</a></h3><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span><span class=lnt>9
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>pandas</span> <span class=k>as</span> <span class=nn>pd</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 6,497개의 와인 샘플 데이터</span>
</span></span><span class=line><span class=cl><span class=n>wine</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>read_csv</span><span class=p>(</span><span class=s1>&#39;https://bit.ly/wine_csv_data&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 기본 5개만 보기</span>
</span></span><span class=line><span class=cl><span class=n>wine</span><span class=o>.</span><span class=n>head</span><span class=p>(</span><span class=mi>5</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 타깃 클래스 0이면 레드와인, 1이면 화이트 와인</span>
</span></span></code></pre></td></tr></table></div></div><table><thead><tr><th>index</th><th>alcohol</th><th>sugar</th><th>pH</th><th>class</th></tr></thead><tbody><tr><td>0</td><td>9.4</td><td>1.9</td><td>3.51</td><td>0.0</td></tr><tr><td>1</td><td>9.8</td><td>2.6</td><td>3.2</td><td>0.0</td></tr><tr><td>2</td><td>9.8</td><td>2.3</td><td>3.26</td><td>0.0</td></tr><tr><td>3</td><td>9.8</td><td>1.9</td><td>3.16</td><td>0.0</td></tr><tr><td>4</td><td>9.4</td><td>1.9</td><td>3.51</td><td>0.0</td></tr></tbody></table><p>판다스에서 제공하는 <code>info()</code> 메서드는 데이터프레임의 각 열의 데이터 타입과 누락된 데이터가 있는지 확인하는데 유용합니다.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>wine</span><span class=o>.</span><span class=n>info</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 결과 값값</span>
</span></span><span class=line><span class=cl><span class=o>&lt;</span><span class=k>class</span> <span class=err>&#39;</span><span class=nc>pandas</span><span class=o>.</span><span class=n>core</span><span class=o>.</span><span class=n>frame</span><span class=o>.</span><span class=n>DataFrame</span><span class=s1>&#39;&gt;</span>
</span></span><span class=line><span class=cl><span class=n>RangeIndex</span><span class=p>:</span> <span class=mi>6497</span> <span class=n>entries</span><span class=p>,</span> <span class=mi>0</span> <span class=n>to</span> <span class=mi>6496</span>
</span></span><span class=line><span class=cl><span class=n>Data</span> <span class=n>columns</span> <span class=p>(</span><span class=n>total</span> <span class=mi>4</span> <span class=n>columns</span><span class=p>):</span>
</span></span><span class=line><span class=cl> <span class=c1>#   Column   Non-Null Count  Dtype</span>
</span></span><span class=line><span class=cl><span class=o>---</span>  <span class=o>------</span>   <span class=o>--------------</span>  <span class=o>-----</span>
</span></span><span class=line><span class=cl> <span class=mi>0</span>   <span class=n>alcohol</span>  <span class=mi>6497</span> <span class=n>non</span><span class=o>-</span><span class=n>null</span>   <span class=n>float64</span>
</span></span><span class=line><span class=cl> <span class=mi>1</span>   <span class=n>sugar</span>    <span class=mi>6497</span> <span class=n>non</span><span class=o>-</span><span class=n>null</span>   <span class=n>float64</span>
</span></span><span class=line><span class=cl> <span class=mi>2</span>   <span class=n>pH</span>       <span class=mi>6497</span> <span class=n>non</span><span class=o>-</span><span class=n>null</span>   <span class=n>float64</span>
</span></span><span class=line><span class=cl> <span class=mi>3</span>   <span class=k>class</span>    <span class=err>6497 </span><span class=nc>non</span><span class=o>-</span><span class=n>null</span>   <span class=n>float64</span>
</span></span><span class=line><span class=cl><span class=n>dtypes</span><span class=p>:</span> <span class=n>float64</span><span class=p>(</span><span class=mi>4</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>memory</span> <span class=n>usage</span><span class=p>:</span> <span class=mf>203.2</span> <span class=n>KB</span>
</span></span></code></pre></td></tr></table></div></div><p><code>describe()</code> 메서드는 열에 대한 간략한 통계를 출력해 줍니다. 최소, 최대, 평균값등을 확인할 수 있습니다.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>wine</span><span class=o>.</span><span class=n>describe</span><span class=p>()</span>
</span></span></code></pre></td></tr></table></div></div><table><thead><tr><th>index</th><th>alcohol</th><th>sugar</th><th>pH</th><th>class</th></tr></thead><tbody><tr><td>count</td><td>6497.0</td><td>6497.0</td><td>6497.0</td><td>6497.0</td></tr><tr><td>mean</td><td>10.49180</td><td>5.4432353</td><td>3.2185</td><td>0.7538</td></tr><tr><td>std</td><td>1.192711</td><td>4.7578037</td><td>0.1607</td><td>0.4307</td></tr><tr><td>min</td><td>8.0</td><td>0.6</td><td>2.72</td><td>0.0</td></tr><tr><td>25%</td><td>9.5</td><td>1.8</td><td>3.11</td><td>1.0</td></tr><tr><td>50%</td><td>10.3</td><td>3.0</td><td>3.21</td><td>1.0</td></tr><tr><td>75%</td><td>11.3</td><td>8.1</td><td>3.32</td><td>1.0</td></tr><tr><td>max</td><td>14.9</td><td>65.8</td><td>4.01</td><td>1.0</td></tr></tbody></table><p>위와 같이 평균, 표준편차, 최소, 최대, 중간값, 1사분위수, 3사분위수를 알 수 있습니다.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 넘파이 배열로 바꾸기</span>
</span></span><span class=line><span class=cl><span class=n>data</span> <span class=o>=</span> <span class=n>wine</span><span class=p>[[</span><span class=s1>&#39;alcohol&#39;</span><span class=p>,</span> <span class=s1>&#39;sugar&#39;</span><span class=p>,</span> <span class=s1>&#39;pH&#39;</span><span class=p>]]</span><span class=o>.</span><span class=n>to_numpy</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>target</span> <span class=o>=</span> <span class=n>wine</span><span class=p>[</span><span class=s1>&#39;class&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>to_numpy</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.model_selection</span> <span class=kn>import</span> <span class=n>train_test_split</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 훈련 세트와 테스트 세트 나누기(결과값 고정(42))</span>
</span></span><span class=line><span class=cl><span class=n>train_input</span><span class=p>,</span> <span class=n>test_input</span><span class=p>,</span> <span class=n>train_target</span><span class=p>,</span> <span class=n>test_target</span> <span class=o>=</span> <span class=n>train_test_split</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>data</span><span class=p>,</span> <span class=n>target</span><span class=p>,</span> <span class=n>test_size</span><span class=o>=</span><span class=mf>0.2</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>train_input</span><span class=o>.</span><span class=n>shape</span><span class=p>,</span> <span class=n>test_input</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span> <span class=c1># 훈련 세트 (5197, 3), 테스트 세트 (1300, 3)</span>
</span></span></code></pre></td></tr></table></div></div><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.preprocessing</span> <span class=kn>import</span> <span class=n>StandardScaler</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 훈련 세트를 전처리</span>
</span></span><span class=line><span class=cl><span class=n>ss</span> <span class=o>=</span> <span class=n>StandardScaler</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>ss</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>train_input</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>train_scaled</span> <span class=o>=</span> <span class=n>ss</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>train_input</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>test_scaled</span> <span class=o>=</span> <span class=n>ss</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>test_input</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.linear_model</span> <span class=kn>import</span> <span class=n>LogisticRegression</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 로지스틱 회귀 모델 훈련</span>
</span></span><span class=line><span class=cl><span class=n>lr</span> <span class=o>=</span> <span class=n>LogisticRegression</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>lr</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>train_scaled</span><span class=p>,</span> <span class=n>train_target</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>lr</span><span class=o>.</span><span class=n>score</span><span class=p>(</span><span class=n>train_scaled</span><span class=p>,</span> <span class=n>train_target</span><span class=p>))</span> <span class=c1># 0.7808350971714451</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>lr</span><span class=o>.</span><span class=n>score</span><span class=p>(</span><span class=n>test_scaled</span><span class=p>,</span> <span class=n>test_target</span><span class=p>))</span> <span class=c1># 0.7776923076923077</span>
</span></span></code></pre></td></tr></table></div></div><p>점수가 높지 않네요. 모델이 과소적합된 경향이 있습니다.<br>대부분의 머신러닝 모델은 이렇게 학습의 결과를 설명하기 어렵습니다.</p><p>이를 해결하기 위해서 결정 트리 모델을 쓰면 조금 더 설명하기 쉽다고 합니다.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.tree</span> <span class=kn>import</span> <span class=n>DecisionTreeClassifier</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 사이킷런의 DecisionTreeClassifier 클래스를 사용</span>
</span></span><span class=line><span class=cl><span class=n>dt</span> <span class=o>=</span> <span class=n>DecisionTreeClassifier</span><span class=p>(</span><span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>dt</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>train_scaled</span><span class=p>,</span> <span class=n>train_target</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 훈련 세트</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>dt</span><span class=o>.</span><span class=n>score</span><span class=p>(</span><span class=n>train_scaled</span><span class=p>,</span> <span class=n>train_target</span><span class=p>))</span> <span class=c1># 0.996921300750433</span>
</span></span><span class=line><span class=cl><span class=c1># 테스트 세트</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>dt</span><span class=o>.</span><span class=n>score</span><span class=p>(</span><span class=n>test_scaled</span><span class=p>,</span> <span class=n>test_target</span><span class=p>))</span> <span class=c1># 0.8592307692307692</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>matplotlib.pyplot</span> <span class=k>as</span> <span class=nn>plt</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.tree</span> <span class=kn>import</span> <span class=n>plot_tree</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span><span class=mi>7</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>plot_tree</span><span class=p>(</span><span class=n>dt</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span></code></pre></td></tr></table></div></div><p>훈련 세트에 대한 점수가 0.996 정도로 매우 높게 나왔습니다. 테스트 세트의 성능은 그에 비해 낮게 나온 것을 확인할 수 있습니다.</p><p>이러한 유형을 과대적합된 모델이라고 합니다.</p><p>아래는 <code>plot_tree()</code> 함수를 이용하여 생성된 트리 이미지입니다. 가장 위는 루트 노트 가장 아래는 리프 노드라고 합니다. 흠..</p><p><img alt=image loading=lazy src=/posts/books/hg-mldl/week-4/images/image-02.webp></p><p>결정 트리 알고리즘에서는 특성값의 스케일이 계산에 영향을 미치지 않습니다. 따라서 표준화 전처리를 할 필요가 없습니다.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span><span class=mi>7</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>plot_tree</span><span class=p>(</span><span class=n>dt</span><span class=p>,</span> <span class=n>max_depth</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>filled</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>feature_names</span><span class=o>=</span><span class=p>[</span><span class=s1>&#39;alcohol&#39;</span><span class=p>,</span> <span class=s1>&#39;sugar&#39;</span><span class=p>,</span> <span class=s1>&#39;pH&#39;</span><span class=p>])</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span></code></pre></td></tr></table></div></div><p><img alt=image loading=lazy src=/posts/books/hg-mldl/week-4/images/image-03.webp></p><p>결정 트리를 보는 방법은 다음과 같습니다.</p><p>박스의 값을 순서대로 보면 아래와 같습니다.</p><p>테스트 조건(sugar)<br>불순도(gini)<br>총 샘플 수(samples)<br>클래스별 샘플 수(value)</p><p>위와 같이 조건에 맞으면 왼쪽 맞지 않으면 오른쪽으로 계속하여 트리가 내려갑니다.</p><p>지니 불순도(Gini Impurity)는 결정 트리에서 노드의 &ldquo;불순한 정도"를 측정하는 지표입니다.</p><p>한 노드에 여러 클래스의 데이터가 섞여 있을수록 불순도가 높고, 한 클래스로만 구성되어 있으면 불순도가 낮습니다.</p><p>뭐 공식이 있긴 한데.. 그냥 결정 트리에서는 각 분할에서 지니 불순도를 최대한 낮추는 방향으로 데이터를 나누는 것이 좋다고 생각하면 됩니다.</p><p>또한 결정 트리는 표준화 전처리 과정이 필요 없기 때문에 아래처럼 바로 값을 확인하고 색상에 대한 구별로 클래스를 구분할 수 있습니다.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>dt</span> <span class=o>=</span> <span class=n>DecisionTreeClassifier</span><span class=p>(</span><span class=n>max_depth</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># 바로 값을 넣어도 됨(표준화 전처리 과정이 필요 없음)</span>
</span></span><span class=line><span class=cl><span class=n>dt</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>train_input</span><span class=p>,</span> <span class=n>train_target</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>dt</span><span class=o>.</span><span class=n>score</span><span class=p>(</span><span class=n>train_input</span><span class=p>,</span> <span class=n>train_target</span><span class=p>))</span> <span class=c1># 0.8454877814123533</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>dt</span><span class=o>.</span><span class=n>score</span><span class=p>(</span><span class=n>test_input</span><span class=p>,</span> <span class=n>test_target</span><span class=p>))</span> <span class=c1># 0.8415384615384616</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>20</span><span class=p>,</span><span class=mi>15</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>plot_tree</span><span class=p>(</span><span class=n>dt</span><span class=p>,</span> <span class=n>filled</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>feature_names</span><span class=o>=</span><span class=p>[</span><span class=s1>&#39;alcohol&#39;</span><span class=p>,</span> <span class=s1>&#39;sugar&#39;</span><span class=p>,</span> <span class=s1>&#39;pH&#39;</span><span class=p>])</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span></code></pre></td></tr></table></div></div><p><img alt=image loading=lazy src=/posts/books/hg-mldl/week-4/images/image-04.webp></p><p>그림을 보면 당도가 1.625보다 크고 4.325보다 작은 와인 중에 알코올 도수가 11.025와 같거나 작은 것이 레드 와인이라고 판단했습니다.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>dt</span><span class=o>.</span><span class=n>feature_importances_</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># alcohol | sugar | pH</span>
</span></span><span class=line><span class=cl><span class=c1># [0.12345626 0.86862934 0.0079144 ]</span>
</span></span></code></pre></td></tr></table></div></div><p><code>feature_importances_</code>를 통해 특성 중요도를 보면 2번째 특성인 당도가 0.87로 특성 중요도가 가장 높습니다.<br>또한 값을 모두 더하면 1이 됩니다.</p><p>결정 트리는 깊이가 너무 깊지 않다면 비교적 설명하기 쉽습니다. 근데 실무에서는 더 복잡할 것 같네요..</p><h2 id=교차-검증과-그리드-서치>교차 검증과 그리드 서치<a hidden class=anchor aria-hidden=true href=#교차-검증과-그리드-서치>#</a></h2><p>테스트 세트로 일반화 성능을 올바르게 예측하려면 가능한 한 테스트 세트를 사용하지 말아야 합니다. 테스트 세트를 사용해 자꾸 성능을 확인하다 보면 점점 테스트 세트에 맞추게 되는 문제가 있습니다.</p><p>모델을 만들고 마지막에 1번만 하는게 좋다고 하네요.</p><h3 id=검증-세트>검증 세트<a hidden class=anchor aria-hidden=true href=#검증-세트>#</a></h3><p>테스트 세트를 사용하지 않으면 모델이 과대적합인지 과소적합인지 판단하기 어렵습니다. 테스트 세트를 사용하지 않고 이를 특정하는 간단한 방법은 훈련 세트를 또 나눠서 검증 세트를 만드는 것입니다.</p><p>훈련 세트: 약 60%, 검증 세트: 약 20%, 테스트 세트 약 20%..</p><p>보통 위와 같은 비율로 나누지만 훈련 데이터가 아주 많다면 테스트 세트와 검증 세트를 조금만 넣어도 문제가 없습니다.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>pandas</span> <span class=k>as</span> <span class=nn>pd</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>wine</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>read_csv</span><span class=p>(</span><span class=s1>&#39;https://bit.ly/wine_csv_data&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>data</span> <span class=o>=</span> <span class=n>wine</span><span class=p>[[</span><span class=s1>&#39;alcohol&#39;</span><span class=p>,</span> <span class=s1>&#39;sugar&#39;</span><span class=p>,</span> <span class=s1>&#39;pH&#39;</span><span class=p>]]</span><span class=o>.</span><span class=n>to_numpy</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>target</span> <span class=o>=</span> <span class=n>wine</span><span class=p>[</span><span class=s1>&#39;class&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>to_numpy</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.model_selection</span> <span class=kn>import</span> <span class=n>train_test_split</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>train_input</span><span class=p>,</span> <span class=n>test_input</span><span class=p>,</span> <span class=n>train_target</span><span class=p>,</span> <span class=n>test_target</span> <span class=o>=</span> <span class=n>train_test_split</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>data</span><span class=p>,</span> <span class=n>target</span><span class=p>,</span> <span class=n>test_size</span><span class=o>=</span><span class=mf>0.2</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># 훈련 세트, 검증 세트 만들기 테스트 사이즈 20%</span>
</span></span><span class=line><span class=cl><span class=n>sub_input</span><span class=p>,</span> <span class=n>val_input</span><span class=p>,</span> <span class=n>sub_target</span><span class=p>,</span> <span class=n>val_target</span> <span class=o>=</span> <span class=n>train_test_split</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>train_input</span><span class=p>,</span> <span class=n>train_target</span><span class=p>,</span> <span class=n>test_size</span><span class=o>=</span><span class=mf>0.2</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>sub_input</span><span class=o>.</span><span class=n>shape</span><span class=p>,</span> <span class=n>val_input</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span> <span class=c1># (4157, 3) (1040, 3)</span>
</span></span><span class=line><span class=cl><span class=c1># 훈련 세트 4157, 검증 세트 1040 나눠짐</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.tree</span> <span class=kn>import</span> <span class=n>DecisionTreeClassifier</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>dt</span> <span class=o>=</span> <span class=n>DecisionTreeClassifier</span><span class=p>(</span><span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>dt</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>sub_input</span><span class=p>,</span> <span class=n>sub_target</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>dt</span><span class=o>.</span><span class=n>score</span><span class=p>(</span><span class=n>sub_input</span><span class=p>,</span> <span class=n>sub_target</span><span class=p>))</span> <span class=c1># 0.9971133028626413</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>dt</span><span class=o>.</span><span class=n>score</span><span class=p>(</span><span class=n>val_input</span><span class=p>,</span> <span class=n>val_target</span><span class=p>))</span> <span class=c1># 0.864423076923077</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=교차-검증>교차 검증<a hidden class=anchor aria-hidden=true href=#교차-검증>#</a></h3><p>교차 검증은 검증 세트를 떼어 내어 평가하는 과정을 여러 번 반복합니다. 그 다음 이 점수를 평균하여 최종 검증 점수를 얻습니다.</p><p>보통 이러한 방법을 n-폴드 교차 검증이라고 하는데 보통 5-폴드 교차 검증이나 10-폴드 교차 검증을 많이 사용합니다.</p><p>이렇게 하면 데이터의 80~90%까지 훈련에 사용할 수 있다고 합니다.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.model_selection</span> <span class=kn>import</span> <span class=n>cross_validate</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># cv값으로 폴드 교차 검증 수를 변경할 수 있음</span>
</span></span><span class=line><span class=cl><span class=n>scores</span> <span class=o>=</span> <span class=n>cross_validate</span><span class=p>(</span><span class=n>dt</span><span class=p>,</span> <span class=n>train_input</span><span class=p>,</span> <span class=n>train_target</span><span class=p>,</span> <span class=n>cv</span><span class=o>=</span><span class=mi>5</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>scores</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1>#{</span>
</span></span><span class=line><span class=cl><span class=c1>#&#39;fit_time&#39;: array([0.01962185, 0.0133481 , 0.01217628, 0.01221108, 0.0117507 ]),</span>
</span></span><span class=line><span class=cl><span class=c1>#&#39;score_time&#39;: array([0.00242043, 0.00203443, 0.00241065, 0.00196838, 0.00201941]),</span>
</span></span><span class=line><span class=cl><span class=c1>#&#39;test_score&#39;: array([0.86923077, 0.84615385, 0.87680462, 0.84889317, 0.83541867])</span>
</span></span><span class=line><span class=cl><span class=c1>#}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>scores</span><span class=p>[</span><span class=s1>&#39;test_score&#39;</span><span class=p>]))</span> <span class=c1># 0.855300214703487</span>
</span></span></code></pre></td></tr></table></div></div><p><code>cross_validate()</code> 함수는 기본적으로 5-폴드 교차 검증을 수행합니다. cv 매개변수에서 폴드 수를 바꿀 수도 있습니다.</p><p>검증 폴드의 점수는 <code>test_score</code>라고 합니다.</p><p>사이킷런의 분할기는 교차 검증에서 폴드를 어떻게 나눌지 결정해 줍니다. <code>StratifiedKFold</code>를 사용하여 앞서 수행한 교차 검증과 동일한 결과를 볼 수 있습니다.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span><span class=lnt>9
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.model_selection</span> <span class=kn>import</span> <span class=n>StratifiedKFold</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>scores</span> <span class=o>=</span> <span class=n>cross_validate</span><span class=p>(</span><span class=n>dt</span><span class=p>,</span> <span class=n>train_input</span><span class=p>,</span> <span class=n>train_target</span><span class=p>,</span> <span class=n>cv</span><span class=o>=</span><span class=n>StratifiedKFold</span><span class=p>())</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>scores</span><span class=p>[</span><span class=s1>&#39;test_score&#39;</span><span class=p>]))</span> <span class=c1># 0.855300214703487</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># n_splits 매개변수는 몇(k) 폴드 교차 검증을 할지 정함</span>
</span></span><span class=line><span class=cl><span class=n>splitter</span> <span class=o>=</span> <span class=n>StratifiedKFold</span><span class=p>(</span><span class=n>n_splits</span><span class=o>=</span><span class=mi>10</span><span class=p>,</span> <span class=n>shuffle</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>scores</span> <span class=o>=</span> <span class=n>cross_validate</span><span class=p>(</span><span class=n>dt</span><span class=p>,</span> <span class=n>train_input</span><span class=p>,</span> <span class=n>train_target</span><span class=p>,</span> <span class=n>cv</span><span class=o>=</span><span class=n>splitter</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>scores</span><span class=p>[</span><span class=s1>&#39;test_score&#39;</span><span class=p>]))</span> <span class=c1># 0.8574181117533719</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=하이퍼파라미터-튜닝>하이퍼파라미터 튜닝<a hidden class=anchor aria-hidden=true href=#하이퍼파라미터-튜닝>#</a></h3><p>모델이 학습할 수 없어서 사용자가 지정해야만 하는 파라미터를 <code>하이퍼파라미터</code>라고 합니다.</p><p>사이킷런의 GridSearchCV 클래슨느 하이퍼파라미터 탐색과 교차 검증을 한 번에 수행합니다.<br>또한, 훈련이 끝나면 모델 중에서 검증 점수가 가장 높은 모델의 매개변수 조합으로 전체 훈련 세트에서 자동으로 다시 모델을 훈련합니다.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.model_selection</span> <span class=kn>import</span> <span class=n>GridSearchCV</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>params</span> <span class=o>=</span> <span class=p>{</span><span class=s1>&#39;min_impurity_decrease&#39;</span><span class=p>:</span> <span class=p>[</span><span class=mf>0.0001</span><span class=p>,</span> <span class=mf>0.0002</span><span class=p>,</span> <span class=mf>0.0003</span><span class=p>,</span> <span class=mf>0.0004</span><span class=p>,</span> <span class=mf>0.0005</span><span class=p>]}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>gs</span> <span class=o>=</span> <span class=n>GridSearchCV</span><span class=p>(</span><span class=n>DecisionTreeClassifier</span><span class=p>(</span><span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>),</span> <span class=n>params</span><span class=p>,</span> <span class=n>n_jobs</span><span class=o>=-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>gs</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>train_input</span><span class=p>,</span> <span class=n>train_target</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>dt</span> <span class=o>=</span> <span class=n>gs</span><span class=o>.</span><span class=n>best_estimator_</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>dt</span><span class=o>.</span><span class=n>score</span><span class=p>(</span><span class=n>train_input</span><span class=p>,</span> <span class=n>train_target</span><span class=p>))</span> <span class=c1># 0.9615162593804117</span>
</span></span><span class=line><span class=cl><span class=c1># 그리드 서치로 찾은 최적의 매개변수 값</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>gs</span><span class=o>.</span><span class=n>best_params_</span><span class=p>)</span> <span class=c1># {&#39;min_impurity_decrease&#39;: 0.0001}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 5번의 교차 검증으로 얻은 점수 출력</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>gs</span><span class=o>.</span><span class=n>cv_results_</span><span class=p>[</span><span class=s1>&#39;mean_test_score&#39;</span><span class=p>])</span> <span class=c1># [0.86819297 0.86453617 0.86492226 0.86780891 0.86761605]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 가장 큰 값의 인덱스 출</span>
</span></span><span class=line><span class=cl><span class=n>best_index</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>argmax</span><span class=p>(</span><span class=n>gs</span><span class=o>.</span><span class=n>cv_results_</span><span class=p>[</span><span class=s1>&#39;mean_test_score&#39;</span><span class=p>])</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>gs</span><span class=o>.</span><span class=n>cv_results_</span><span class=p>[</span><span class=s1>&#39;params&#39;</span><span class=p>][</span><span class=n>best_index</span><span class=p>])</span> <span class=c1># {&#39;min_impurity_decrease&#39;: 0.0001}</span>
</span></span></code></pre></td></tr></table></div></div><p>위와 같이 최적의 매개변수를 가져오는 방법을 실습합니다.</p><p>조금 더 복잡한 매개변수 조합을 아래와 같습니다. 결정 트리에서 <code>min_impurity_decrease</code>는 노드를 분할하기 위한 불순도 감소 최소량을 지정합니다. <code>max_depth</code>로 트리의 깊이를 제한하고 <code>min_samples_split</code>로 노드를 나누기 위한 최소 샘플수 를 고릅니다.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>params</span> <span class=o>=</span> <span class=p>{</span><span class=s1>&#39;min_impurity_decrease&#39;</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=mf>0.0001</span><span class=p>,</span> <span class=mf>0.001</span><span class=p>,</span> <span class=mf>0.0001</span><span class=p>),</span>
</span></span><span class=line><span class=cl>          <span class=s1>&#39;max_depth&#39;</span><span class=p>:</span> <span class=nb>range</span><span class=p>(</span><span class=mi>5</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>1</span><span class=p>),</span>
</span></span><span class=line><span class=cl>          <span class=s1>&#39;min_samples_split&#39;</span><span class=p>:</span> <span class=nb>range</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=mi>100</span><span class=p>,</span> <span class=mi>10</span><span class=p>)</span>
</span></span><span class=line><span class=cl>          <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>gs</span> <span class=o>=</span> <span class=n>GridSearchCV</span><span class=p>(</span><span class=n>DecisionTreeClassifier</span><span class=p>(</span><span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>),</span> <span class=n>params</span><span class=p>,</span> <span class=n>n_jobs</span><span class=o>=-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>gs</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>train_input</span><span class=p>,</span> <span class=n>train_target</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>gs</span><span class=o>.</span><span class=n>best_params_</span><span class=p>)</span> <span class=c1># {&#39;max_depth&#39;: 14, &#39;min_impurity_decrease&#39;: np.float64(0.0004), &#39;min_samples_split&#39;: 12}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>max</span><span class=p>(</span><span class=n>gs</span><span class=o>.</span><span class=n>cv_results_</span><span class=p>[</span><span class=s1>&#39;mean_test_score&#39;</span><span class=p>]))</span> <span class=c1># 0.8683865773302731</span>
</span></span></code></pre></td></tr></table></div></div><p>넘파일 arange() 함수는 첫 번째 매개변수 값에서 시작하여 두 번째 매개변수에 도달할 떄까지 세 번째 매개변수를 계속 더한 배열을 만듭니다.</p><p>아래와 같이 매개변수를 만들어서 총 9 _ 15 _ 10 = 1350개에. 5-폴드 교차 검증을 수행하므로 6750개의 모델이 생성됩니다.</p><p><code>min_impurity_decrease: pythonnp.arange(0.0001, 0.001, 0.0001)</code></p><p>[0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008, 0.0009]: 총 9개 값</p><p><code>max_depth: pythonrange(5, 20, 1)</code></p><p>[5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]: 총 15개 값</p><p><code>min_samples_split: pythonrange(2, 100, 10)</code></p><p>[2, 12, 22, 32, 42, 52, 62, 72, 82, 92]: 총 10개 값</p><p>이 값을 통해 최상의 매개변수 조합을 확인할 수 있으며, 최상의 교차 검증 점수도 확인할 수 있습니다.</p><h3 id=랜덤-서치>랜덤 서치<a hidden class=anchor aria-hidden=true href=#랜덤-서치>#</a></h3><p>매개변수의 값이 수치일 떄 값의 범위나 간격을 미리 정하기 어려울 수 있습니다. 이럴 때는 랜덤 서치를 사용하면 좋습니다.</p><p>확률 분포로 파라미터 정의하는 방식입니다. 싸이파이 라이브러리를 이용해서 예제를 실습합니다.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>scipy.stats</span> <span class=kn>import</span> <span class=n>uniform</span><span class=p>,</span> <span class=n>randint</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>rgen</span> <span class=o>=</span> <span class=n>randint</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>10</span><span class=p>)</span> <span class=c1># 0~9 사이 정수를 균등하게 선택</span>
</span></span><span class=line><span class=cl><span class=n>rgen</span><span class=o>.</span><span class=n>rvs</span><span class=p>(</span><span class=mi>10</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>np</span><span class=o>.</span><span class=n>unique</span><span class=p>(</span><span class=n>rgen</span><span class=o>.</span><span class=n>rvs</span><span class=p>(</span><span class=mi>1000</span><span class=p>),</span> <span class=n>return_counts</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>ugen</span> <span class=o>=</span> <span class=n>uniform</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span> <span class=c1># 0~1 사이 실수를 균등하게 선택</span>
</span></span><span class=line><span class=cl><span class=n>ugen</span><span class=o>.</span><span class=n>rvs</span><span class=p>(</span><span class=mi>10</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>params</span> <span class=o>=</span> <span class=p>{</span><span class=s1>&#39;min_impurity_decrease&#39;</span><span class=p>:</span> <span class=n>uniform</span><span class=p>(</span><span class=mf>0.0001</span><span class=p>,</span> <span class=mf>0.001</span><span class=p>),</span>
</span></span><span class=line><span class=cl>          <span class=s1>&#39;max_depth&#39;</span><span class=p>:</span> <span class=n>randint</span><span class=p>(</span><span class=mi>20</span><span class=p>,</span> <span class=mi>50</span><span class=p>),</span>
</span></span><span class=line><span class=cl>          <span class=s1>&#39;min_samples_split&#39;</span><span class=p>:</span> <span class=n>randint</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=mi>25</span><span class=p>),</span>
</span></span><span class=line><span class=cl>          <span class=s1>&#39;min_samples_leaf&#39;</span><span class=p>:</span> <span class=n>randint</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>25</span><span class=p>),</span>
</span></span><span class=line><span class=cl>          <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.model_selection</span> <span class=kn>import</span> <span class=n>RandomizedSearchCV</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>gs</span> <span class=o>=</span> <span class=n>RandomizedSearchCV</span><span class=p>(</span><span class=n>DecisionTreeClassifier</span><span class=p>(</span><span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>),</span> <span class=n>params</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                        <span class=n>n_iter</span><span class=o>=</span><span class=mi>100</span><span class=p>,</span> <span class=n>n_jobs</span><span class=o>=-</span><span class=mi>1</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>gs</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>train_input</span><span class=p>,</span> <span class=n>train_target</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>gs</span><span class=o>.</span><span class=n>best_params_</span><span class=p>)</span> <span class=c1># {&#39;max_depth&#39;: 39, &#39;min_impurity_decrease&#39;: np.float64(0.00034102546602601173), &#39;min_samples_leaf&#39;: 7, &#39;min_samples_split&#39;: 13}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>max</span><span class=p>(</span><span class=n>gs</span><span class=o>.</span><span class=n>cv_results_</span><span class=p>[</span><span class=s1>&#39;mean_test_score&#39;</span><span class=p>]))</span> <span class=c1># 0.8695428296438884</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>dt</span> <span class=o>=</span> <span class=n>gs</span><span class=o>.</span><span class=n>best_estimator_</span> <span class=c1># 최적 모델 가져오기</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>dt</span><span class=o>.</span><span class=n>score</span><span class=p>(</span><span class=n>test_input</span><span class=p>,</span> <span class=n>test_target</span><span class=p>))</span> <span class=c1># 0.86</span>
</span></span></code></pre></td></tr></table></div></div><p>최종 검증 점수는 모든 폴드의 검증 점수를 평균하여 계산합니다.</p><h2 id=트리의-앙상블>트리의 앙상블<a hidden class=anchor aria-hidden=true href=#트리의-앙상블>#</a></h2><p>가장 좋은 알고리즘이 있다고 해서 다른 알고리즘을 배울 필요가 없는 것은 아닙니다.</p><p>보편적으로 성능이 좋아 널리 사용되는 알고리즘이 있지만 문제마다 다를 수 있습니다.</p><h3 id=정형-데이터와-비정형-데이터>정형 데이터와 비정형 데이터<a hidden class=anchor aria-hidden=true href=#정형-데이터와-비정형-데이터>#</a></h3><p>정형 데이터: CSV나 데이터베이스 혹은 엑셀로 저장하기 쉬운 데이터
비정형 데이터: 텍스트 데이터, 사진, 디지털 음악 등, NoSQL 같은 데이터</p><p>정형 데이터를 다루는데 가장 뛰어난 성과를 내는 알고리즘은 <em>앙상블 학습</em>입니다.</p><p>비정형 데이터는 <em>신경망 알고리즘</em>이 좋다고 합니다.</p><h3 id=랜덤-포레스트>랜덤 포레스트<a hidden class=anchor aria-hidden=true href=#랜덤-포레스트>#</a></h3><p>랜덤 포레스트(Random Forest)는 여러 개의 결정 트리를 합쳐서 더 강력한 모델을 만드는 앙상블 기법입니다.
핵심 아이디어는 나무 한 그루보다는 숲이 더 안정적이듯이, 결정 트리 하나보다는 여러 개를 합치면 더 좋은 성능을 낼 수 있습니다.</p><ul><li>부트스트랩 샘플링: 원본 데이터에서 중복을 허용해서 여러 개의 서로 다른 훈련 세트를 만듦</li><li>특성 랜덤 선택: 각 노드에서 전체 특성 중 일부만 랜덤하게 선택해서 분할 기준을 정함</li><li>여러 트리 훈련: 각각 다른 데이터와 다른 특성으로 여러 개의 결정 트리를 훈련</li><li>투표로 결정: 예측할 때 모든 트리의 결과를 종합 (분류: 다수결, 회귀: 평균)</li></ul><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>pandas</span> <span class=k>as</span> <span class=nn>pd</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.model_selection</span> <span class=kn>import</span> <span class=n>train_test_split</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>wine</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>read_csv</span><span class=p>(</span><span class=s1>&#39;https://bit.ly/wine_csv_data&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>data</span> <span class=o>=</span> <span class=n>wine</span><span class=p>[[</span><span class=s1>&#39;alcohol&#39;</span><span class=p>,</span> <span class=s1>&#39;sugar&#39;</span><span class=p>,</span> <span class=s1>&#39;pH&#39;</span><span class=p>]]</span><span class=o>.</span><span class=n>to_numpy</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>target</span> <span class=o>=</span> <span class=n>wine</span><span class=p>[</span><span class=s1>&#39;class&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>to_numpy</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 훈련 및 테스트 데이터 생성</span>
</span></span><span class=line><span class=cl><span class=n>train_input</span><span class=p>,</span> <span class=n>test_input</span><span class=p>,</span> <span class=n>train_target</span><span class=p>,</span> <span class=n>test_target</span> <span class=o>=</span> <span class=n>train_test_split</span><span class=p>(</span><span class=n>data</span><span class=p>,</span> <span class=n>target</span><span class=p>,</span> <span class=n>test_size</span><span class=o>=</span><span class=mf>0.2</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.model_selection</span> <span class=kn>import</span> <span class=n>cross_validate</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.ensemble</span> <span class=kn>import</span> <span class=n>RandomForestClassifier</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># -1로 하면 모든 CPU  코어를 사용함</span>
</span></span><span class=line><span class=cl><span class=n>rf</span> <span class=o>=</span> <span class=n>RandomForestClassifier</span><span class=p>(</span><span class=n>n_jobs</span><span class=o>=-</span><span class=mi>1</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># return_train_score true로 지정하면 검증 점수뿐만 아니라 훈련 세트에 대한 점수도 같이 반환</span>
</span></span><span class=line><span class=cl><span class=n>scores</span> <span class=o>=</span> <span class=n>cross_validate</span><span class=p>(</span><span class=n>rf</span><span class=p>,</span> <span class=n>train_input</span><span class=p>,</span> <span class=n>train_target</span><span class=p>,</span> <span class=n>return_train_score</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>n_jobs</span><span class=o>=-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>scores</span><span class=p>[</span><span class=s1>&#39;train_score&#39;</span><span class=p>]),</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>scores</span><span class=p>[</span><span class=s1>&#39;test_score&#39;</span><span class=p>]))</span> <span class=c1># 0.9973541965122431 0.8905151032797809</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>rf</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>train_input</span><span class=p>,</span> <span class=n>train_target</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># 결정 트리의 특성 중요도 출력(합은 1)</span>
</span></span><span class=line><span class=cl><span class=c1># [알코올 도수, 당도, ph]</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>rf</span><span class=o>.</span><span class=n>feature_importances_</span><span class=p>)</span> <span class=c1># [0.23167441 0.50039841 0.26792718]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># oob_score true로 지정하여 OOB(Out Of Bag) 점수를 출력</span>
</span></span><span class=line><span class=cl><span class=n>rf</span> <span class=o>=</span> <span class=n>RandomForestClassifier</span><span class=p>(</span><span class=n>oob_score</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>n_jobs</span><span class=o>=-</span><span class=mi>1</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>rf</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>train_input</span><span class=p>,</span> <span class=n>train_target</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>rf</span><span class=o>.</span><span class=n>oob_score_</span><span class=p>)</span> <span class=c1># 0.8934000384837406</span>
</span></span></code></pre></td></tr></table></div></div><p><code>RandomForestClassifier</code>는 기본적으로 100개의 결정 트리를 사용합니다.</p><p>랜덤 포레스트의 경우는 특성 중요도가 5장 1절에서 만든 결정 트리의 특성 중요도가 다르게 나왔습니다.</p><p>다르게 나온 이유는 랜덤 포레스트가 특성의 일부를 랜덤하게 선택하여 결정 트리를 훈련하기 때문입니다. 그 결과 하나의 특성에 과도하게 집중하지 않고 좀 더 많은 특성이 훈련에 기여할 기회를 얻습니다.</p><h3 id=엑스트라-트리>엑스트라 트리<a hidden class=anchor aria-hidden=true href=#엑스트라-트리>#</a></h3><p>엑스트라 트리는 랜덤 포레스트와 매우 비슷하게 동작합니다.</p><p>랜덤 포레스트와 엑스트라 트리의 차이점은 부트스트랩 샘플을 사용하지 않는다는 점입니다. 즉각 결정 트리를 만들 때 전체 훈련 세트를 사용합니다.</p><p>엑스트라 트리가 무작위성이 좀 더 크기 때문에 랜덤 포레스트보다 더 많은 결정 트리를 훈련해야 합니다. 하지만 랜덤하게 노드를 분할하기 때문에 빠른 계산 속도가 엑스트라 트리의 장점입니다.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.ensemble</span> <span class=kn>import</span> <span class=n>ExtraTreesClassifier</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>et</span> <span class=o>=</span> <span class=n>ExtraTreesClassifier</span><span class=p>(</span><span class=n>n_jobs</span><span class=o>=-</span><span class=mi>1</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>scores</span> <span class=o>=</span> <span class=n>cross_validate</span><span class=p>(</span><span class=n>et</span><span class=p>,</span> <span class=n>train_input</span><span class=p>,</span> <span class=n>train_target</span><span class=p>,</span> <span class=n>return_train_score</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>n_jobs</span><span class=o>=-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>scores</span><span class=p>[</span><span class=s1>&#39;train_score&#39;</span><span class=p>]),</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>scores</span><span class=p>[</span><span class=s1>&#39;test_score&#39;</span><span class=p>]))</span> <span class=c1># 0.9974503966084433 0.8887848893166506</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>et</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>train_input</span><span class=p>,</span> <span class=n>train_target</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># [알코올 도수, 당도, ph]</span>
</span></span><span class=line><span class=cl><span class=c1># [0.20183568 0.52242907 0.27573525]</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>et</span><span class=o>.</span><span class=n>feature_importances_</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=그레이디언트-부스팅>그레이디언트 부스팅<a hidden class=anchor aria-hidden=true href=#그레이디언트-부스팅>#</a></h3><p>그레이디언트 부스팅 (Gradient Boosting)은 약한 모델들을 순차적으로 학습시켜서 이전 모델의 오차를 보정하는 방식</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.ensemble</span> <span class=kn>import</span> <span class=n>GradientBoostingClassifier</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>gb</span> <span class=o>=</span> <span class=n>GradientBoostingClassifier</span><span class=p>(</span><span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>scores</span> <span class=o>=</span> <span class=n>cross_validate</span><span class=p>(</span><span class=n>gb</span><span class=p>,</span> <span class=n>train_input</span><span class=p>,</span> <span class=n>train_target</span><span class=p>,</span> <span class=n>return_train_score</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>n_jobs</span><span class=o>=-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>scores</span><span class=p>[</span><span class=s1>&#39;train_score&#39;</span><span class=p>]),</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>scores</span><span class=p>[</span><span class=s1>&#39;test_score&#39;</span><span class=p>]))</span> <span class=c1># 0.8881086892152563 0.8720430147331015</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 결정 트리 500개로 늘림</span>
</span></span><span class=line><span class=cl><span class=n>gb</span> <span class=o>=</span> <span class=n>GradientBoostingClassifier</span><span class=p>(</span><span class=n>n_estimators</span><span class=o>=</span><span class=mi>500</span><span class=p>,</span> <span class=n>learning_rate</span><span class=o>=</span><span class=mf>0.2</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>scores</span> <span class=o>=</span> <span class=n>cross_validate</span><span class=p>(</span><span class=n>gb</span><span class=p>,</span> <span class=n>train_input</span><span class=p>,</span> <span class=n>train_target</span><span class=p>,</span> <span class=n>return_train_score</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>n_jobs</span><span class=o>=-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>scores</span><span class=p>[</span><span class=s1>&#39;train_score&#39;</span><span class=p>]),</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>scores</span><span class=p>[</span><span class=s1>&#39;test_score&#39;</span><span class=p>]))</span> <span class=c1># 0.9464595437171814 0.8780082549788999</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>gb</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>train_input</span><span class=p>,</span> <span class=n>train_target</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># [알코올 도수, 당도, ph]</span>
</span></span><span class=line><span class=cl><span class=c1># [0.15887763 0.6799705  0.16115187]</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>gb</span><span class=o>.</span><span class=n>feature_importances_</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>랜덤 포레스트와 달리 순차적 학습(병렬화 어려움) 합니다. 그레이디언트 부스팅이 랜덤 포레스트보다 조금 더 높은 성능을 얻읈 수 있습니다. 하지만 순서대로 트리를 추가하기 때문에 훈련 속도가 느립니다.</p><h3 id=히스토그램-기반-그레이디언트-부스팅>히스토그램 기반 그레이디언트 부스팅<a hidden class=anchor aria-hidden=true href=#히스토그램-기반-그레이디언트-부스팅>#</a></h3><p>정형 데이터를 다루는 머신러닝 알고리즘 중에 가장 인기가 높은 알고리즘입니다.</p><p>입력 특성을 256개의 구간으로 나눠서 진행하기 때문에 노드를 분할할 때 최적의 분할을 매우 빠르게 찾을 수 있습니다.</p><p>기존 그레이디언트 부스팅 대비 10-20배 빠르면서도 비슷하거나 더 좋은 성능을 보여줘서 현재 가장 인기 있는 방법 중 하나입니다.</p><p><code>permutation_importance()</code> 함수가 반환하는 객체는 반복하여 얻은 특성 중요도, 평균, 표준 편차를 담고 있습니다.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.experimental</span> <span class=kn>import</span> <span class=n>enable_hist_gradient_boosting</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.ensemble</span> <span class=kn>import</span> <span class=n>HistGradientBoostingClassifier</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>hgb</span> <span class=o>=</span> <span class=n>HistGradientBoostingClassifier</span><span class=p>(</span><span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>scores</span> <span class=o>=</span> <span class=n>cross_validate</span><span class=p>(</span><span class=n>hgb</span><span class=p>,</span> <span class=n>train_input</span><span class=p>,</span> <span class=n>train_target</span><span class=p>,</span> <span class=n>return_train_score</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>n_jobs</span><span class=o>=-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>scores</span><span class=p>[</span><span class=s1>&#39;train_score&#39;</span><span class=p>]),</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>scores</span><span class=p>[</span><span class=s1>&#39;test_score&#39;</span><span class=p>]))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># permutation_importance는 특성을 하나씩 랜덤하게 섞어서 모델의 성능이 변화하는지를 관찰하여 어떤 특성이 중요한지를 계산함</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.inspection</span> <span class=kn>import</span> <span class=n>permutation_importance</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>hgb</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>train_input</span><span class=p>,</span> <span class=n>train_target</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># n_repeats 매개변수는 랜덤하게 섞을 횟수를 지정 기본값은 5</span>
</span></span><span class=line><span class=cl><span class=n>result</span> <span class=o>=</span> <span class=n>permutation_importance</span><span class=p>(</span><span class=n>hgb</span><span class=p>,</span> <span class=n>train_input</span><span class=p>,</span> <span class=n>train_target</span><span class=p>,</span> <span class=n>n_repeats</span><span class=o>=</span><span class=mi>10</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>,</span> <span class=n>n_jobs</span><span class=o>=-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># [알코올 도수, 당도, ph]</span>
</span></span><span class=line><span class=cl><span class=c1># [0.08876275 0.23438522 0.08027708]</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>result</span><span class=o>.</span><span class=n>importances_mean</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1>#print(result.importances)</span>
</span></span><span class=line><span class=cl><span class=c1>#print(result.importances_std)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>result</span> <span class=o>=</span> <span class=n>permutation_importance</span><span class=p>(</span><span class=n>hgb</span><span class=p>,</span> <span class=n>test_input</span><span class=p>,</span> <span class=n>test_target</span><span class=p>,</span> <span class=n>n_repeats</span><span class=o>=</span><span class=mi>10</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>,</span> <span class=n>n_jobs</span><span class=o>=-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># [알코올 도수, 당도, ph]</span>
</span></span><span class=line><span class=cl><span class=c1># [0.05969231 0.20238462 0.049     ]</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>result</span><span class=o>.</span><span class=n>importances_mean</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>hgb</span><span class=o>.</span><span class=n>score</span><span class=p>(</span><span class=n>test_input</span><span class=p>,</span> <span class=n>test_target</span><span class=p>)</span> <span class=c1># 0.8723076923076923 (87% 정확도)</span>
</span></span></code></pre></td></tr></table></div></div><p>이외에도 XGBoost 라이브러리를 이용하여 와인 데이터의 교차 검증 점수를 확인할 수 있습니다.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>xgboost</span> <span class=kn>import</span> <span class=n>XGBClassifier</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># hist 히스토그램 기반 그레이디언트 부스팅 사용</span>
</span></span><span class=line><span class=cl><span class=n>xgb</span> <span class=o>=</span> <span class=n>XGBClassifier</span><span class=p>(</span><span class=n>tree_method</span><span class=o>=</span><span class=s1>&#39;hist&#39;</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>scores</span> <span class=o>=</span> <span class=n>cross_validate</span><span class=p>(</span><span class=n>xgb</span><span class=p>,</span> <span class=n>train_input</span><span class=p>,</span> <span class=n>train_target</span><span class=p>,</span> <span class=n>return_train_score</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>n_jobs</span><span class=o>=-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 0.9567059184812372 0.8783915747390243</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>scores</span><span class=p>[</span><span class=s1>&#39;train_score&#39;</span><span class=p>]),</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>scores</span><span class=p>[</span><span class=s1>&#39;test_score&#39;</span><span class=p>]))</span>
</span></span></code></pre></td></tr></table></div></div><p>마이크로소프트에서 만든 LightGBM으로도 확인할 수 있습니다..!</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>lightgbm</span> <span class=kn>import</span> <span class=n>LGBMClassifier</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>lgb</span> <span class=o>=</span> <span class=n>LGBMClassifier</span><span class=p>(</span><span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>scores</span> <span class=o>=</span> <span class=n>cross_validate</span><span class=p>(</span><span class=n>lgb</span><span class=p>,</span> <span class=n>train_input</span><span class=p>,</span> <span class=n>train_target</span><span class=p>,</span> <span class=n>return_train_score</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>n_jobs</span><span class=o>=-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 0.935828414851749 0.8801251203079884</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>scores</span><span class=p>[</span><span class=s1>&#39;train_score&#39;</span><span class=p>]),</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>scores</span><span class=p>[</span><span class=s1>&#39;test_score&#39;</span><span class=p>]))</span>
</span></span></code></pre></td></tr></table></div></div><p>여러 앙상블 학습을 배웠으며, 히스토그램 기반 그레이디언트 부스팅 알고리즘이 제일.. 좋아 보이네요.</p></div><footer class=post-footer><ul class=post-tags></ul><nav class=paginav><a class=prev href=https://haservi.github.io/posts/books/hg-mldl/week-5/><span class=title>« 이전 페이지</span><br><span>[혼공머신] 5주차 학습 내용 정리</span>
</a><a class=next href=https://haservi.github.io/posts/books/hg-mldl/week-3/><span class=title>다음 페이지 »</span><br><span>[혼공머신] 3주차 학습 내용 정리</span></a></nav></footer><section class=comments><script>loadComment();function loadComment(){document.body.className.includes("dark")?theme="photon-dark":theme="boxy-light";let e=document.createElement("script");e.src="https://utteranc.es/client.js",e.setAttribute("repo","haservi/haservi.github.io"),e.setAttribute("issue-term","pathname"),e.setAttribute("theme",theme),e.setAttribute("crossorigin","anonymous"),e.setAttribute("async",""),document.querySelector("section.comments").innerHTML="",document.querySelector("section.comments").appendChild(e)}</script></section></article></main><footer class=footer><span>&copy; 2025 <a href=https://haservi.github.io/>Halog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script src=https://cdnjs.cloudflare.com/ajax/libs/medium-zoom/1.0.6/medium-zoom.min.js integrity="sha512-N9IJRoc3LaP3NDoiGkcPa4gG94kapGpaA5Zq9/Dr04uf5TbLFU5q0o8AbRhLKUUlp8QFS2u7S+Yti0U7QtuZvQ==" crossorigin=anonymous referrerpolicy=no-referrer></script><script>const images=Array.from(document.querySelectorAll(".post-content img"));images.forEach(e=>{mediumZoom(e,{margin:0,background:"#1d1e20",scrollOffset:40,container:null,template:null})})</script><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark")),loadComment()})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="복사";function s(){t.innerHTML="복사 완료!",setTimeout(()=>{t.innerHTML="복사"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>